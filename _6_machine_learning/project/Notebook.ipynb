{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82fff94e",
   "metadata": {},
   "source": [
    "<b>Problem-1: \n",
    "You are hired by one of the leading news channels CNBE who wants to analyze recent elections. This survey was conducted on 1525 voters with 9 variables. You have to build a model, to predict which party a voter will vote for on the basis of the given information, to create an exit poll that will help in predicting overall win and seats covered by a particular party.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d0bf180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20aba45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Election_Data.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54adcf7",
   "metadata": {},
   "source": [
    "1.1.\tData description and Inferences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6aa4f1",
   "metadata": {},
   "source": [
    "1.2.\tData walkthrough (head() .info(), shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3127f3",
   "metadata": {},
   "source": [
    "1.3.\tData validation (Null check, Summary and Skewness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b686aa",
   "metadata": {},
   "source": [
    "1.4.\tExploratory Data Analysis (Null, Data Types, Shape, Univariate & Bivariate Analysis, Outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a0785b",
   "metadata": {},
   "source": [
    "1.5.\tInferences Distribution plots, Box plots, Correlation plots, Plots for Categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0b95a5",
   "metadata": {},
   "source": [
    "1.6.\tEncode the data for the features with String Values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e47081f",
   "metadata": {},
   "source": [
    "1.7.\tIs Scaling necessary or not? Check the 5-point summary to support the Scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dc3854",
   "metadata": {},
   "source": [
    "1.8.\tObject data should be converted into Categorical/Number type and fit to models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14ac7a0",
   "metadata": {},
   "source": [
    "1.9.\tRatio for the split and train-test-split should be explained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f0b69e",
   "metadata": {},
   "source": [
    "1.10.\tApply Logistic Regression and LDA and Interpret inferences of both models. Logical explanation to select the hyper parameters involved in each model. Comment if model is overfit or underfit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c26d5d4",
   "metadata": {},
   "source": [
    "1.11.\tApply KNN and Naïve Bayes and explain the choice of Hyper parameters. Calculate Train-Test accuracies for each model. Comment if the model is overfit or underfit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a8a1ab",
   "metadata": {},
   "source": [
    "1.12.\tModel Tuning, Bagging and Boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1d4055",
   "metadata": {},
   "source": [
    "1.13.\tApply GridSearchCV on all models and make models on best params. Explain the hyper parameters for GridSearch. Comment on feature importance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76267d8e",
   "metadata": {},
   "source": [
    "1.14.\tPerformance Metrics for train and test sets using Accuracy, Confusion Matrix, ROC curve and ROC_AUC score, classification report. Compare and comment on all model’s performance metrics in a table. Describe which model is optimized, also explain which model is best for the current problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62a4dce",
   "metadata": {},
   "source": [
    "1.15.\tExplain the insights and recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf73428",
   "metadata": {},
   "source": [
    "<b>Problem-2: \n",
    "In this project, we are going to work on the inaugural corpora from the nltk in Python. We will be looking at the following speeches of the Presidents of the United States of America:\n",
    "\n",
    "President Franklin D. Roosevelt in 1941\n",
    "President John F. Kennedy in 1961\n",
    "President Richard Nixon in 1973\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b4581a",
   "metadata": {},
   "source": [
    "2.1.\tFind the number of characters, words and sentences for the mentioned documents. (Hint: use .words(), .raw(), .sent() for extracting counts)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d8fe2f",
   "metadata": {},
   "source": [
    "2.2.\tRemove all the stopwords from the three speeches. Show the word count before and after the removal of stopwords. Show a sample sentence after the removal of stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff257044",
   "metadata": {},
   "source": [
    "2.3.\tWhich word occurs the most number of times in his inaugural address for each president? Mention the top three words. (after removing the stopwords)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3090558",
   "metadata": {},
   "source": [
    "2.4.\tPlot the word cloud of each of the three speeches. (after removing the stopwords). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85abb6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
